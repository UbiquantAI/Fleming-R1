# Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning

<p align="center">
          ğŸ¤— <a href="https://huggingface.co/UbiquantAI/Fleming-R1-7B">Fleming-R1-7B</a> | ğŸ¤— <a href="https://huggingface.co/UbiquantAI/Fleming-R1-32B">Fleming-R1-32B</a> | ğŸ“‘ <a href="https://github.com/UbiquantAI/Fleming-R1/blob/main/paper/Fleming-R1.pdf">Paper</a> | <b>ä¸­æ–‡</b> | <a href="https://github.com/UbiquantAI/Fleming-R1/blob/main/README.md">English</a>
<p>

## ğŸ“– æ¨¡å‹ç®€ä»‹

Fleming-R1 æ˜¯ä¸€æ¬¾é¢å‘åŒ»å­¦åœºæ™¯çš„æ¨ç†æ¨¡å‹ï¼Œèƒ½å¤Ÿå¯¹å¤æ‚é—®é¢˜è¿›è¡Œé€æ­¥åˆ†æå¹¶ç»™å‡ºå¯é ç­”æ¡ˆã€‚æ¨¡å‹é‡‡ç”¨â€œæ€ç»´é“¾å†·å¯åŠ¨â€ä¸å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒèŒƒå¼ã€‚åœ¨å¤šé¡¹åŒ»å­¦è¯„æµ‹ä¸­ï¼Œ7B ç‰ˆæœ¬åœ¨åŒé‡çº§ä¸­è¾¾åˆ° SOTAï¼›32B ç‰ˆæœ¬çš„è¡¨ç°æ¥è¿‘æ›´å¤§è§„æ¨¡çš„ GPT-OSS-120Bï¼Œå¹¶åœ¨ä¸­æ–‡ä»»åŠ¡ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚

**æ¨¡å‹ç‰¹ç‚¹ï¼š**

* **é¢å‘æ¨ç†çš„æ•°æ®ç­–ç•¥** ç»“åˆå…¬å¼€åŒ»å­¦æ•°æ®é›†ä¸çŸ¥è¯†å›¾è°±ï¼Œæé«˜äº†å¯¹ç½•è§ç–¾ç—…ã€è¯ç‰©å’Œå¤šè·³æ¨ç†é“¾çš„è¦†ç›–ï¼›
* **æ€ç»´é“¾å†·å¯åŠ¨** ä½¿ç”¨ä»æ•™å¸ˆæ¨¡å‹ä¸­æç‚¼çš„é«˜è´¨é‡æ¨ç†è½¨è¿¹ï¼Œå¼•å¯¼æ¨¡å‹æŒæ¡åŸºæœ¬çš„æ¨ç†æ¨¡å¼ï¼›
* **ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ** é€šè¿‡è‡ªé€‚åº”è´Ÿæ ·æœ¬æŒ–æ˜ï¼Œæé«˜æ¨¡å‹é¢å¯¹å›°éš¾é—®é¢˜æ—¶çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“¦ å‘å¸ƒç‰ˆæœ¬

- **Fleming-R1-7B** â€”â€” åŸºäº Qwen2.5-7B è®­ç»ƒ
  ğŸ¤— [`UbiquantAI/Fleming-R1-7B`](https://huggingface.co/UbiquantAI/Fleming-R1-7B)
- **Fleming-R1-32B** â€”â€” åŸºäº Qwen3-32B è®­ç»ƒ
  ğŸ¤— [`UbiquantAI/Fleming-R1-32B`](https://huggingface.co/UbiquantAI/Fleming-R1-32B)

## ğŸ“Š æ€§èƒ½è¡¨ç°

### ä¸»è¦åŸºå‡†æµ‹è¯•ç»“æœ

<div align="center">
  <img src="images/exp_result.png" alt="åŸºå‡†æµ‹è¯•ç»“æœ" width="60%">
</div>

### æ¨ç†èƒ½åŠ›å¯¹æ¯”

åœ¨è¡¡é‡åŒ»å­¦æ¨ç†èƒ½åŠ›çš„MedXpertQAè¯„æµ‹ä¸­ï¼ŒFleming-R1è¶…è¿‡äº†åŒé‡çº§ç”šè‡³æ›´å¤§é‡çº§çš„æ¨¡å‹ï¼Œå’Œä¸€äº›é—­æºæ¨¡å‹æ•ˆæœé½å¹³ã€‚

<div align="center">
  <img src="images/size_compare.png" alt="size compare" width=60%">
</div>

## ğŸ”§ å¿«é€Ÿå¼€å§‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "UbiquantAI/Fleming-R1-7B" # UbiquantAI/Fleming-R1-32B

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "What should I do if I suddenly develop a fever?"
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)

model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

# parsing thinking content
output = tokenizer.decode(output_ids, skip_special_tokens=True).strip("\n")
thinking_content = output.split("<think>")[-1].split("</think>")[0]
content = output.split("</think>")[-1]

print("####thinking content:\n", thinking_content)
print("\n")
print("####answer:\n", content)

```

## âš ï¸å®‰å…¨å£°æ˜

æœ¬é¡¹ç›®ä»…ä¾›ç ”ç©¶ä¸éä¸´åºŠå‚è€ƒï¼›ä¸å¾—ç”¨äºå®é™…è¯Šæ–­æˆ–æ²»ç–—å†³ç­–ã€‚
è¾“å‡ºçš„æ¨ç†è½¨è¿¹ä»…ä¸ºæ¨¡å‹ç”Ÿæˆçš„å¯å®¡è®¡ä¸­é—´è¿‡ç¨‹ï¼Œä¸ç­‰äºåŒ»å­¦æ„è§ã€‚
åœ¨åŒ»ç–—åœºæ™¯ä¸­åŠ¡å¿…ç”±ä¸“ä¸šäººå‘˜è¿›è¡Œå¤æ ¸ä¸æŠŠå…³ï¼Œå¹¶éµå®ˆæ‰€åœ¨åœ°åŒºçš„æ³•å¾‹æ³•è§„ä¸éšç§åˆè§„è¦æ±‚ã€‚

## ğŸ“š å¼•ç”¨

```bibtex
@misc{fleming-r1,
  title = {Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning},
  author = {Chi Liu and Derek Li and Yan Shu and Robin Chen and Derek Duan and Teng Fang and Bryan Dai},
  year = {2025},
  url = {https://github.com/UbiquantAI/Fleming-R1/blob/main/paper/Fleming-R1.pdf},
}
```
